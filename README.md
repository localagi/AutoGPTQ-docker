# Llama-GPTQ-docker

Sophisticated docker builds for parent projects [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ)

![example workflow](https://github.com/localagi/autogptq-docker/actions/workflows/publish-docker.yml/badge.svg?branch=main)

Easy setup. Compatible. Tweakable. Scaleable.

# WIP

`source alias.autogptq`

`autogptq basic_usage.py`

`autogptq quant_with_alpaca.py --pretrained_model_dir "facebook/opt-125m" --per_gpu_max_memory 4 --quant_batch_size 16`
